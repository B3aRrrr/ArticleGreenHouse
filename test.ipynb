{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dmitry\\Desktop\\Lab5\\ArticleGreenHouse\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:35: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
      "  from tensorflow.tsl.python.lib.core import pywrap_ml_dtypes\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from pcse_gym.envs.common_env import PCSEEnv\n",
    "from pcse.fileinput import CABOFileReader, YAMLCropDataProvider\n",
    "from pcse.util import WOFOST80SiteDataProvider\n",
    "from GreenHouseEnv.green_house import GreenHousePCSEEnv\n",
    "from pcse_gym.utils.eval import EvalCallback, determine_and_log_optimum\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.summary import create_file_writer\n",
    "from stable_baselines3 import A2C, SAC, PPO, TD3\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from datetime import datetime\n",
    "from tensorflow.summary import scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and configure a PCSE-Gym environment\n",
    "# Note: the following configuration has not been chosen for its realism\n",
    "env = GreenHousePCSEEnv(\n",
    "    model_config='Wofost80_NWLP_FD.conf',\n",
    "    agro_config=os.path.join(os.getcwd(),'pcse_gym','envs','configs','agro','potato_cropcalendar.yaml'),\n",
    "    crop_parameters=YAMLCropDataProvider(force_reload=True),\n",
    "    site_parameters=WOFOST80SiteDataProvider(WAV=10,  # Initial amount of water in total soil profile [cm]\n",
    "                                             NAVAILI=10,  # Amount of N available in the pool at initialization of the system [kg/ha]\n",
    "                                             PAVAILI=50,  # Amount of P available in the pool at initialization of the system [kg/ha]\n",
    "                                             KAVAILI=100,  # Amount of K available in the pool at initialization of the system [kg/ha]\n",
    "                                             ),\n",
    "    soil_parameters=CABOFileReader(os.path.join(os.getcwd(),'pcse_gym','envs','configs','soil','ec3.CAB')),\n",
    ")\n",
    "\n",
    "# Reset/initialize the environment to obtain an initial observation\n",
    "o = env.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPO (Proximal Policy Optimization):\n",
    "```python\n",
    "total_timesteps (int): #Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "callback (BaseCallback, optional):# Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "log_interval (int):# Интервал для записи логов.\n",
    "eval_env (gym.Env, optional): #Среда для оценки производительности модели.\n",
    "eval_freq (int): #Частота оценки (в терминах количества шагов).\n",
    "n_eval_episodes (int): #Количество эпизодов для оценки модели.\n",
    "#Множество других аргументов, связанных с настройками обучения и гиперпараметрами.\n",
    "```\n",
    "\n",
    "\n",
    "SAC (Soft Actor-Critic):\n",
    "```python\n",
    "total_timesteps (int): # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "callback (BaseCallback, optional):#  Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "log_interval (int): #Интервал для записи логов.\n",
    "eval_env (gym.Env, optional): #Среда для оценки производительности модели.\n",
    "eval_freq (int): #Частота оценки (в терминах количества шагов).\n",
    "n_eval_episodes (int): #Количество эпизодов для оценки модели.\n",
    "# Множество других аргументов, связанных с настройками обучения и гиперпараметрами.\n",
    "```\n",
    "\n",
    "TD3 (Twin Delayed Deep Deterministic Policy Gradient):\n",
    "```python\n",
    "total_timesteps (int): # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "callback (BaseCallback, optional): #Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "log_interval (int):# Интервал для записи логов.\n",
    "eval_env (gym.Env, optional):# Среда для оценки производительности модели.\n",
    "eval_freq (int): #Частота оценки (в терминах количества шагов).\n",
    "n_eval_episodes (int): #Количество эпизодов для оценки модели.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_LOGS_DIR=os.path.join(\n",
    "    os.getcwd(),\"tensorboard_logs\"\n",
    "    )\n",
    "if not os.path.exists(TENSORBOARD_LOGS_DIR):\n",
    "    os.makedirs(TENSORBOARD_LOGS_DIR)\n",
    "ENV_DIR = os.path.join(TENSORBOARD_LOGS_DIR,env.__class__.name)\n",
    "if not os.path.exists(ENV_DIR):\n",
    "    os.makedirs(ENV_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, writer=None):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.rewards = []\n",
    "        self.writer = writer  # Передайте SummaryWriter\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.model.ep_info_buffer:\n",
    "            reward = self.model.ep_info_buffer[0].get('r', 0)  # Получаем значение 'r' из первого элемента или 0, если 'r' отсутствует\n",
    "        else:\n",
    "            reward = 0  # Обработка случая, когда очередь пуста\n",
    "\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "        # Запишите вознаграждение в SummaryWriter\n",
    "        with self.writer.as_default():\n",
    "            scalar(\"Reward\", reward, step=self.num_timesteps)\n",
    "\n",
    "        # Здесь вы также можете записывать другие параметры среды\n",
    "\n",
    "        return True\n",
    "\n",
    "    def close(self) -> None:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sac_variants = {\n",
    "    0: {'batch_size': 64, 'ent_coef': 'auto','learning_rate': 0.003,'learning_starts': 100,'buffer_size': 100000,},\n",
    "    1: {'batch_size': 64, 'ent_coef': 'auto', 'learning_rate': 0.001, 'learning_starts': 100, 'buffer_size': 100000},\n",
    "    2: {'batch_size': 64, 'ent_coef': 0.01, 'learning_rate': 0.003, 'learning_starts': 500, 'buffer_size': 50000},\n",
    "    3: {'batch_size': 32, 'ent_coef': 'auto', 'learning_rate': 0.002, 'learning_starts': 200, 'buffer_size': 150000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "\n",
    "name_model = f'SAC'\n",
    "\n",
    "MODEL_DIR = os.path.join(ENV_DIR,name_model)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "for var in sac_variants.keys():\n",
    "    name_model_var= f'var_{var}'\n",
    "\n",
    "    MODEL_DIR_VAR = os.path.join(MODEL_DIR,name_model_var)\n",
    "    if not os.path.exists(MODEL_DIR_VAR):\n",
    "        os.makedirs(MODEL_DIR_VAR)\n",
    "\n",
    "    sac_hyperparams = sac_variants[var]\n",
    "\n",
    "    model_sac = SAC(\"MultiInputPolicy\", env, verbose=1,**sac_hyperparams)\n",
    "    # Создайте директорию для записи данных TensorBoard\n",
    "    log_dir = os.path.join(\n",
    "        MODEL_DIR_VAR,\n",
    "        date\n",
    "        )  # Замените это на путь к вашей директории\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Создайте SummaryWriter\n",
    "    writer = create_file_writer(log_dir)\n",
    "\n",
    "    model_sac.learn(\n",
    "        total_timesteps=5e5, # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "        callback = CustomCallback(writer=writer),#  Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "        log_interval=1e2, #Интервал для записи логов.\n",
    "        progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A2C model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2c_variants = {\n",
    "    0: {'n_steps': 5,'ent_coef': 0.01,'learning_rate': 0.0007,'vf_coef': 0.25,'max_grad_norm': 0.5,},\n",
    "    1: {'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.001, 'vf_coef': 0.2, 'max_grad_norm': 0.5},\n",
    "    2: {'n_steps': 10, 'ent_coef': 0.015, 'learning_rate': 0.0005, 'vf_coef': 0.3, 'max_grad_norm': 0.6},\n",
    "    3: {'n_steps': 5, 'ent_coef': 0.02, 'learning_rate': 0.0007, 'vf_coef': 0.15, 'max_grad_norm': 0.7},\n",
    "}\n",
    "# hyperparameter_variations = {\n",
    "#     0: {\n",
    "#         \"learning_rate\": 5e-4,\n",
    "#         \"n_steps\": 2048,\n",
    "#         \"gamma\": 0.98,\n",
    "#         \"gae_lambda\": 0.95,\n",
    "#         \"ent_coef\": 0.0,\n",
    "#         \"vf_coef\": 0.5,\n",
    "#         \"max_grad_norm\": 0.5,\n",
    "#         \"use_sde\": True,\n",
    "#         \"sde_sample_freq\": 50,\n",
    "#         \"normalize_advantage\": True,\n",
    "#         \"stats_window_size\": 50,\n",
    "#     },\n",
    "#     1: {\n",
    "#         \"learning_rate\": 3e-4,\n",
    "#         \"n_steps\": 1024,\n",
    "#         \"gamma\": 0.99,\n",
    "#         \"gae_lambda\": 0.96,\n",
    "#         \"ent_coef\": 0.02,\n",
    "#         \"vf_coef\": 0.4,\n",
    "#         \"max_grad_norm\": 0.6,\n",
    "#         \"use_sde\": False,\n",
    "#         \"sde_sample_freq\": -1,\n",
    "#         \"normalize_advantage\": False,\n",
    "#         \"stats_window_size\": 200,\n",
    "#     },\n",
    "#     2: {\n",
    "#         \"learning_rate\": 7e-4,\n",
    "#         \"n_steps\": 4096,\n",
    "#         \"gamma\": 0.97,\n",
    "#         \"gae_lambda\": 0.97,\n",
    "#         \"ent_coef\": 0.01,\n",
    "#         \"vf_coef\": 0.6,\n",
    "#         \"max_grad_norm\": 0.4,\n",
    "#         \"use_sde\": True,\n",
    "#         \"sde_sample_freq\": 100,\n",
    "#         \"normalize_advantage\": True,\n",
    "#         \"stats_window_size\": 100,\n",
    "#     },\n",
    "#     3: {\n",
    "#         \"learning_rate\": 1e-3,\n",
    "#         \"n_steps\": 2560,\n",
    "#         \"gamma\": 0.95,\n",
    "#         \"gae_lambda\": 0.98,\n",
    "#         \"ent_coef\": 0.015,\n",
    "#         \"vf_coef\": 0.45,\n",
    "#         \"max_grad_norm\": 0.55,\n",
    "#         \"use_sde\": False,\n",
    "#         \"sde_sample_freq\": -1,\n",
    "#         \"normalize_advantage\": True,\n",
    "#         \"stats_window_size\": 150,\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "\n",
    "name_model = f'A2C'\n",
    "\n",
    "MODEL_DIR = os.path.join(ENV_DIR,name_model)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "\n",
    "for var in a2c_variants.keys():\n",
    "    name_model_var= f'var_{var}'\n",
    "\n",
    "    MODEL_DIR_VAR = os.path.join(MODEL_DIR,name_model_var)\n",
    "    if not os.path.exists(MODEL_DIR_VAR):\n",
    "        os.makedirs(MODEL_DIR_VAR)\n",
    "\n",
    "    a2c_hyperparams = a2c_variants[var]\n",
    "    model_a2c = A2C(\"MultiInputPolicy\", env, verbose=1,**a2c_hyperparams)\n",
    "\n",
    "    # Создайте директорию для записи данных TensorBoard\n",
    "    log_dir = os.path.join(\n",
    "        MODEL_DIR_VAR,\n",
    "        date\n",
    "        )  # Замените это на путь к вашей директории\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Создайте SummaryWriter\n",
    "    writer = create_file_writer(log_dir)\n",
    "\n",
    "    model_a2c.learn(\n",
    "        total_timesteps=1,#e6, # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "        callback = CustomCallback(writer=writer),#  Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "        log_interval=1e2, #Интервал для записи логов.\n",
    "        progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_variants = {\n",
    "    0: {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 2048,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 10,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.95,\n",
    "    \"clip_range\": 0.2,\n",
    "    \"ent_coef\": 0.0,\n",
    "    \"vf_coef\": 0.5,\n",
    "    \"max_grad_norm\": 0.5,\n",
    "    \"sde_sample_freq\": -1,\n",
    "    \"stats_window_size\": 100,\n",
    "},\n",
    "    1: {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"n_steps\": 4096,\n",
    "    \"batch_size\": 128,\n",
    "    \"n_epochs\": 5,\n",
    "    \"gamma\": 0.95,\n",
    "    \"gae_lambda\": 0.98,\n",
    "    \"clip_range\": 0.1,\n",
    "    \"ent_coef\": 0.02,\n",
    "    \"vf_coef\": 0.6,\n",
    "    \"max_grad_norm\": 0.6,\n",
    "    \"sde_sample_freq\": -1,\n",
    "    \"stats_window_size\": 50,\n",
    "},\n",
    "    2: {\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"n_steps\": 1024,\n",
    "    \"batch_size\": 32,\n",
    "    \"n_epochs\": 20,\n",
    "    \"gamma\": 0.99,\n",
    "    \"gae_lambda\": 0.9,\n",
    "    \"clip_range\": 0.25,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"vf_coef\": 0.4,\n",
    "    \"max_grad_norm\": 0.6,\n",
    "    \"sde_sample_freq\": -1,\n",
    "    \"stats_window_size\": 200,\n",
    "}\n",
    ",\n",
    "    3: {\n",
    "        \"learning_rate\": 5e-4,\n",
    "        \"n_steps\": 3072,\n",
    "        \"batch_size\": 64,\n",
    "        \"n_epochs\": 15,\n",
    "        \"gamma\": 0.98,\n",
    "        \"gae_lambda\": 0.92,\n",
    "        \"clip_range\": 0.15,\n",
    "        \"ent_coef\": 0.015,\n",
    "        \"vf_coef\": 0.45,\n",
    "        \"max_grad_norm\": 0.7,\n",
    "        \"sde_sample_freq\": -1,\n",
    "        \"stats_window_size\": 150,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "\n",
    "name_model = f'PPO'\n",
    "\n",
    "MODEL_DIR = os.path.join(ENV_DIR,name_model)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    \n",
    "for var in ppo_variants.keys():\n",
    "    name_model_var = f'var_{var}'\n",
    "\n",
    "    MODEL_DIR_VAR = os.path.join(MODEL_DIR,name_model_var)\n",
    "    if not os.path.exists(MODEL_DIR_VAR):\n",
    "        os.makedirs(MODEL_DIR_VAR)\n",
    "\n",
    "    ppo_hyperparams = ppo_variants[var]\n",
    "    model_ppo = PPO(\"MultiInputPolicy\", env, verbose=1,**ppo_hyperparams)\n",
    "\n",
    "    # Создайте директорию для записи данных TensorBoard\n",
    "    log_dir = os.path.join(\n",
    "        MODEL_DIR_VAR,\n",
    "        date\n",
    "        )  # Замените это на путь к вашей директории\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Создайте SummaryWriter\n",
    "    writer = create_file_writer(log_dir)\n",
    "\n",
    "    model_ppo.learn(\n",
    "        total_timesteps=1,#e6, # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "        callback = CustomCallback(writer=writer),#  Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "        log_interval=1e2, #Интервал для записи логов.\n",
    "        progress_bar=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "td3_variants = {\n",
    "    0: {\n",
    "    \"learning_rate\": 5e-4,\n",
    "    \"buffer_size\": 500_000,\n",
    "    \"learning_starts\": 200,\n",
    "    \"batch_size\": 64,\n",
    "    \"tau\": 0.01,\n",
    "    \"gamma\": 0.98,\n",
    "    \"train_freq\": (2, \"episode\"),\n",
    "    \"gradient_steps\": 50,\n",
    "    \"policy_delay\": 3,\n",
    "    \"target_policy_noise\": 0.15,\n",
    "    \"target_noise_clip\": 0.4,\n",
    "    \"stats_window_size\": 50,\n",
    "}\n",
    ",\n",
    "    1: {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"buffer_size\": 1_000_000,\n",
    "    \"learning_starts\": 100,\n",
    "    \"batch_size\": 100,\n",
    "    \"tau\": 0.005,\n",
    "    \"gamma\": 0.99,\n",
    "    \"train_freq\": (4, \"step\"),\n",
    "    \"gradient_steps\": 100,\n",
    "    \"policy_delay\": 1,\n",
    "    \"target_policy_noise\": 0.1,\n",
    "    \"target_noise_clip\": 0.3,\n",
    "    \"stats_window_size\": 200,\n",
    "}\n",
    ",\n",
    "    2: {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"buffer_size\": 750_000,\n",
    "    \"learning_starts\": 150,\n",
    "    \"batch_size\": 75,\n",
    "    \"tau\": 0.0075,\n",
    "    \"gamma\": 0.97,\n",
    "    \"train_freq\": (3, \"episode\"),\n",
    "    \"gradient_steps\": 75,\n",
    "    \"policy_delay\": 2,\n",
    "    \"target_policy_noise\": 0.125,\n",
    "    \"target_noise_clip\": 0.35,\n",
    "    \"stats_window_size\": 150,\n",
    "}\n",
    ",\n",
    "    3: {\n",
    "    \"learning_rate\": 3e-3,\n",
    "    \"buffer_size\": 1_250_000,\n",
    "    \"learning_starts\": 50,\n",
    "    \"batch_size\": 50,\n",
    "    \"tau\": 0.0025,\n",
    "    \"gamma\": 0.95,\n",
    "    \"train_freq\": (1, \"step\"),\n",
    "    \"gradient_steps\": 200,\n",
    "    \"policy_delay\": 4,\n",
    "    \"target_policy_noise\": 0.2,\n",
    "    \"target_noise_clip\": 0.45,\n",
    "    \"stats_window_size\": 250,\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.now().strftime(\"%Y-%m-%d__%H-%M-%S\")\n",
    "\n",
    "name_model = f'TD3'\n",
    "\n",
    "MODEL_DIR = os.path.join(ENV_DIR,name_model)\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)\n",
    "    \n",
    "for var in td3_variants.keys():\n",
    "    name_model_var = f'var_{var}'\n",
    "\n",
    "    MODEL_DIR_VAR = os.path.join(MODEL_DIR,name_model_var)\n",
    "    if not os.path.exists(MODEL_DIR_VAR):\n",
    "        os.makedirs(MODEL_DIR_VAR)\n",
    "        \n",
    "    td3_hyperparams = td3_variants[var]\n",
    "    model_td3 = TD3(\"MultiInputPolicy\", env, verbose=1,**td3_hyperparams)\n",
    "\n",
    "    # Создайте директорию для записи данных TensorBoard\n",
    "    log_dir = os.path.join(\n",
    "        MODEL_DIR_VAR,\n",
    "        date\n",
    "        )  # Замените это на путь к вашей директории\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    # Создайте SummaryWriter\n",
    "    writer = create_file_writer(log_dir)\n",
    "\n",
    "    model_td3.learn(\n",
    "        total_timesteps=1, #1e6, # Общее количество шагов времени, в течение которых будет произведено обучение.\n",
    "        callback = CustomCallback(writer=writer),#  Обратный вызов (callback) для записи промежуточных результатов обучения.\n",
    "        log_interval=1e2, #Интервал для записи логов.\n",
    "        progress_bar=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
